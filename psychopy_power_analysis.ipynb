{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from scipy import signal\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from scipy.signal import kaiserord, lfilter, firwin, freqz, butter, filtfilt, convolve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Counter  O1/theta  O1/alpha  O1/betaL  O1/betaH  O1/gamma  O2/theta  \\\n",
       "0          0     0.598     0.750     0.959     0.850     0.640     0.630   \n",
       "1          1     0.725     0.918     1.052     0.883     0.582     0.568   \n",
       "2          2     0.809     1.082     1.081     0.868     0.529     0.494   \n",
       "3          3     0.808     1.178     1.037     0.801     0.489     0.415   \n",
       "4          4     0.721     1.161     0.937     0.695     0.466     0.354   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "595      115     0.299     0.428     0.171     0.174     0.184     0.091   \n",
       "596      116     0.357     0.420     0.189     0.184     0.190     0.090   \n",
       "597      117     0.406     0.452     0.198     0.197     0.196     0.095   \n",
       "598      118     0.433     0.521     0.195     0.206     0.205     0.106   \n",
       "599      119     0.427     0.611     0.186     0.215     0.217     0.124   \n",
       "\n",
       "     O2/alpha  O2/betaL  O2/betaH  O2/gamma          TIME  \n",
       "0       0.540     0.099     0.244     0.518  1.606229e+09  \n",
       "1       0.481     0.095     0.225     0.488  1.606229e+09  \n",
       "2       0.476     0.122     0.219     0.470  1.606229e+09  \n",
       "3       0.515     0.172     0.218     0.452  1.606229e+09  \n",
       "4       0.587     0.233     0.218     0.427  1.606229e+09  \n",
       "..        ...       ...       ...       ...           ...  \n",
       "595     0.802     0.633     0.155     0.105  1.606229e+09  \n",
       "596     0.839     0.612     0.164     0.108  1.606229e+09  \n",
       "597     0.905     0.534     0.179     0.113  1.606229e+09  \n",
       "598     1.005     0.431     0.197     0.119  1.606229e+09  \n",
       "599     1.110     0.335     0.213     0.129  1.606229e+09  \n",
       "\n",
       "[600 rows x 12 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"recordings/psychopy_sultan_recording_\" # 0 to 3\n",
    "num_targets = 4\n",
    "targets = [None] * num_targets\n",
    "channels = ['P7', 'O1', 'O2', 'P8'] # data channels\n",
    "for i in range(num_targets):\n",
    "    targets[i] = pd.read_csv(dataset_name+str(i)+'.csv')\n",
    "    targets[i]['Unnamed: 0'] = [i % 120 for i in range(len(targets[i].index))]\n",
    "    targets[i].rename(columns = {'Unnamed: 0': 'Counter'}, inplace=True)\n",
    "targets[0].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length target 0 = 600\n",
      "length target 1 = 600\n",
      "length target 2 = 600\n",
      "length target 3 = 600\n"
     ]
    }
   ],
   "source": [
    "def cut_uneven_datasets(df_list):\n",
    "    # use this function if the datasets are of uneven length - chop to minimum df size\n",
    "    cutoff_list = [len(df_list[i].index) for i in range(num_targets)]\n",
    "    cutoff = min(cutoff_list)\n",
    "    for i in range(len(cutoff_list)):\n",
    "        keep_indicies = set(range(df_list[i].shape[0])) - set(range(cutoff, df_list[i].shape[0]))\n",
    "        df_list[i] = df_list[i].take(list(keep_indicies))\n",
    "        # make sure each df same length\n",
    "        print('new length of dataset {} = {}'.format(i+1, len(df_list[i].index)))\n",
    "    return df_list\n",
    "        \n",
    "# check size - make sure each target is the same length\n",
    "for i in range(num_targets):\n",
    "    print('length target {} = {}'.format(i, len(targets[i].index)))\n",
    "\n",
    "# fix length\n",
    "# targets = cut_uneven_datasets(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy unfiltered data\n",
    "original_data = [None] * num_targets\n",
    "for i in range(num_targets):\n",
    "    original_data[i] = pd.read_csv(dataset_name+str(i)+'.csv')\n",
    "    original_data[i]['Unnamed: 0'] = [i % 120 for i in range(len(original_data[i].index))]\n",
    "    original_data[i].rename(columns = {'Unnamed: 0': 'Counter'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
